{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in ./venv/lib/python3.11/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: soundfile in ./venv/lib/python3.11/site-packages (0.13.1)\n",
      "Requirement already satisfied: datasets in ./venv/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: codecarbon in ./venv/lib/python3.11/site-packages (2.8.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./venv/lib/python3.11/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in ./venv/lib/python3.11/site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./venv/lib/python3.11/site-packages (from librosa) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in ./venv/lib/python3.11/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=0.14 in ./venv/lib/python3.11/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./venv/lib/python3.11/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./venv/lib/python3.11/site-packages (from librosa) (0.61.0)\n",
      "Requirement already satisfied: pooch>=1.1 in ./venv/lib/python3.11/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./venv/lib/python3.11/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./venv/lib/python3.11/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./venv/lib/python3.11/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./venv/lib/python3.11/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./venv/lib/python3.11/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.11/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./venv/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./venv/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./venv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./venv/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.11/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./venv/lib/python3.11/site-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: arrow in ./venv/lib/python3.11/site-packages (from codecarbon) (1.3.0)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.11/site-packages (from codecarbon) (8.1.8)\n",
      "Requirement already satisfied: fief-client[cli] in ./venv/lib/python3.11/site-packages (from codecarbon) (0.20.0)\n",
      "Requirement already satisfied: prometheus-client in ./venv/lib/python3.11/site-packages (from codecarbon) (0.21.1)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.11/site-packages (from codecarbon) (6.1.1)\n",
      "Requirement already satisfied: py-cpuinfo in ./venv/lib/python3.11/site-packages (from codecarbon) (9.0.0)\n",
      "Requirement already satisfied: pynvml in ./venv/lib/python3.11/site-packages (from codecarbon) (12.0.0)\n",
      "Requirement already satisfied: questionary in ./venv/lib/python3.11/site-packages (from codecarbon) (2.1.0)\n",
      "Requirement already satisfied: rapidfuzz in ./venv/lib/python3.11/site-packages (from codecarbon) (3.11.0)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.11/site-packages (from codecarbon) (13.9.4)\n",
      "Requirement already satisfied: typer in ./venv/lib/python3.11/site-packages (from codecarbon) (0.15.1)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.11/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./venv/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./venv/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.11/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in ./venv/lib/python3.11/site-packages (from arrow->codecarbon) (2.9.0.post0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./venv/lib/python3.11/site-packages (from arrow->codecarbon) (2.9.0.20241206)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in ./venv/lib/python3.11/site-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
      "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in ./venv/lib/python3.11/site-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
      "Requirement already satisfied: yaspin in ./venv/lib/python3.11/site-packages (from fief-client[cli]->codecarbon) (3.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in ./venv/lib/python3.11/site-packages (from pynvml->codecarbon) (12.570.86)\n",
      "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in ./venv/lib/python3.11/site-packages (from questionary->codecarbon) (3.0.50)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.11/site-packages (from rich->codecarbon) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.11/site-packages (from rich->codecarbon) (2.19.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./venv/lib/python3.11/site-packages (from typer->codecarbon) (1.5.4)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.7)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.14.0)\n",
      "Requirement already satisfied: cryptography>=3.4 in ./venv/lib/python3.11/site-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (44.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.11/site-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
      "Requirement already satisfied: termcolor<2.4.0,>=2.2.0 in ./venv/lib/python3.11/site-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install librosa soundfile datasets codecarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "from pathlib import Path\n",
    "from codecarbon import EmissionsTracker  # For energy monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sign in to Hugging Face for datasets\n",
    "token = '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'\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset in streaming mode\n",
    "dataset = load_dataset(\"rfcx/frugalai\", streaming=True)\n",
    "\n",
    "# Limit the number of samples for training\n",
    "max_samples = 1000  # Adjust based on your needs\n",
    "dataset['train'] = dataset['train'].take(max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define the SpectrogramIterableDataset class with advanced preprocessing\n",
    "class SpectrogramIterableDataset(IterableDataset):\n",
    "    def __init__(self, iterable_dataset, n_fft=1024, hop_length=256, n_mels=64, target_size=(64, 64)):\n",
    "        self.dataset = iterable_dataset\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def add_noise(self, audio, noise_level=0.005):\n",
    "        \"\"\"Add random noise to the audio signal.\"\"\"\n",
    "        noise = np.random.randn(len(audio)) * noise_level\n",
    "        return audio + noise\n",
    "\n",
    "    def time_stretch(self, audio, rate=1.0):\n",
    "        \"\"\"Apply time-stretching to the audio signal.\"\"\"\n",
    "        return librosa.effects.time_stretch(audio, rate=rate)\n",
    "\n",
    "    def pitch_shift(self, audio, sampling_rate, n_steps=2):\n",
    "        \"\"\"Apply pitch-shifting to the audio signal.\"\"\"\n",
    "        return librosa.effects.pitch_shift(audio, sr=sampling_rate, n_steps=n_steps)\n",
    "\n",
    "    def frequency_masking(self, spectrogram, max_mask_freq=16):\n",
    "        \"\"\"Randomly mask frequency bands in the spectrogram.\"\"\"\n",
    "        if spectrogram.shape[0] <= 1:  # Skip if spectrogram is too small\n",
    "            return spectrogram\n",
    "        freq_mask = np.random.randint(1, min(max_mask_freq, spectrogram.shape[0]) + 1)  # Ensure valid range\n",
    "        start = np.random.randint(0, spectrogram.shape[0] - freq_mask)\n",
    "        spectrogram[start:start + freq_mask, :] = 0\n",
    "        return spectrogram\n",
    "\n",
    "    def time_masking(self, spectrogram, max_mask_time=16):\n",
    "        \"\"\"Randomly mask time segments in the spectrogram.\"\"\"\n",
    "        if spectrogram.shape[1] <= 1:  # Skip if spectrogram is too small\n",
    "            return spectrogram\n",
    "        time_mask = np.random.randint(1, min(max_mask_time, spectrogram.shape[1]) + 1)  # Ensure valid range\n",
    "        start = np.random.randint(0, spectrogram.shape[1] - time_mask)\n",
    "        spectrogram[:, start:start + time_mask] = 0\n",
    "        return spectrogram\n",
    "\n",
    "    def compute_delta_features(self, spectrogram):\n",
    "        \"\"\"Compute delta and delta-delta features for temporal dynamics.\"\"\"\n",
    "        delta = librosa.feature.delta(spectrogram)\n",
    "        delta_delta = librosa.feature.delta(spectrogram, order=2)\n",
    "        return np.stack([spectrogram, delta, delta_delta], axis=0)\n",
    "\n",
    "    def process_audio(self, audio_array, sampling_rate):\n",
    "        # Pad the audio signal if it's too short\n",
    "        if len(audio_array) < self.n_fft:\n",
    "            audio_array = np.pad(audio_array, (0, self.n_fft - len(audio_array)), mode='constant')\n",
    "\n",
    "        # Data augmentation: Add noise, time-stretch, and pitch-shift\n",
    "        audio_array = self.add_noise(audio_array)\n",
    "        audio_array = self.time_stretch(audio_array, rate=np.random.uniform(0.9, 1.1))\n",
    "        audio_array = self.pitch_shift(audio_array, sampling_rate, n_steps=np.random.randint(-2, 2))\n",
    "\n",
    "        # Generate Mel spectrogram\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(\n",
    "            y=audio_array, sr=sampling_rate, n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length, n_mels=self.n_mels\n",
    "        )\n",
    "        # Convert to log scale (dB)\n",
    "        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "        # Normalize to zero mean and unit variance\n",
    "        if np.std(log_mel_spectrogram) > 0:  # Avoid division by zero\n",
    "            log_mel_spectrogram = (log_mel_spectrogram - np.mean(log_mel_spectrogram)) / np.std(log_mel_spectrogram)\n",
    "        else:\n",
    "            log_mel_spectrogram = np.zeros_like(log_mel_spectrogram)  # Handle case where std is zero\n",
    "\n",
    "        # Apply frequency and time masking\n",
    "        log_mel_spectrogram = self.frequency_masking(log_mel_spectrogram)\n",
    "        log_mel_spectrogram = self.time_masking(log_mel_spectrogram)\n",
    "\n",
    "        # Compute delta features\n",
    "        log_mel_spectrogram = self.compute_delta_features(log_mel_spectrogram)\n",
    "\n",
    "        # Resize to target size\n",
    "        log_mel_spectrogram = librosa.util.fix_length(log_mel_spectrogram, size=self.target_size[1], axis=2)\n",
    "        log_mel_spectrogram = librosa.util.fix_length(log_mel_spectrogram, size=self.target_size[0], axis=1)\n",
    "\n",
    "        # Return the spectrogram in its original shape (3D: [channels, height, width])\n",
    "        return torch.tensor(log_mel_spectrogram, dtype=torch.float32)  # Shape: (3, height, width)\n",
    "    def __iter__(self):\n",
    "        for sample in iter(self.dataset):\n",
    "            audio_array = sample['audio']['array']\n",
    "            sampling_rate = sample['audio']['sampling_rate']\n",
    "            label = sample['label']\n",
    "            \n",
    "            # Process audio to spectrogram\n",
    "            spectrogram = self.process_audio(audio_array, sampling_rate)\n",
    "            \n",
    "            yield spectrogram, label\n",
    "    def __len__(self):\n",
    "        # Counts items manually\n",
    "        return sum(1 for _ in iter(self.dataset)) # Counts the number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the train IterableDataset\n",
    "wrapped_train_dataset = SpectrogramIterableDataset(dataset['train'])\n",
    "\n",
    "# Create DataLoader with smaller batch size\n",
    "batch_size = 16  # Reduce from 32\n",
    "train_loader = DataLoader(\n",
    "    wrapped_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0  # Set to 0 if CPU resources are limited\n",
    ")\n",
    "\n",
    "# Wrap the test IterableDataset\n",
    "wrapped_test_dataset = SpectrogramIterableDataset(dataset['test'])\n",
    "\n",
    "# Create DataLoader with smaller batch size\n",
    "batch_size = 16  # Reduce from 32\n",
    "test_loader = DataLoader(\n",
    "    wrapped_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0  # Set to 0 if CPU resources are limited\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)  # Input channels = 3 (delta features)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)  # Adjusted for target_size=(64, 64)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:18:27] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 11:18:27] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 11:18:33] No CPU tracking mode found. Falling back on CPU constant mode. \n",
      " Mac OS detected: Please install Intel Power Gadget or enable PowerMetrics sudo to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 11:18:34] CPU Model on constant consumption mode: Intel(R) Core(TM) i5-8257U CPU @ 1.40GHz\n",
      "[codecarbon INFO @ 11:18:34] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 11:18:34] No GPU found.\n",
      "[codecarbon INFO @ 11:18:34] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 11:18:34]   Platform system: macOS-10.16-x86_64-i386-64bit\n",
      "[codecarbon INFO @ 11:18:34]   Python version: 3.11.7\n",
      "[codecarbon INFO @ 11:18:34]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 11:18:34]   Available RAM : 8.000 GB\n",
      "[codecarbon INFO @ 11:18:34]   CPU count: 8\n",
      "[codecarbon INFO @ 11:18:34]   CPU model: Intel(R) Core(TM) i5-8257U CPU @ 1.40GHz\n",
      "[codecarbon INFO @ 11:18:34]   GPU count: None\n",
      "[codecarbon INFO @ 11:18:34]   GPU model: None\n",
      "[codecarbon INFO @ 11:18:35] Saving emissions data to file /Users/sarahlenet/Desktop/FrugalAI/emissions.csv\n",
      "[codecarbon INFO @ 11:18:50] Energy consumed for RAM : 0.000013 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 11:18:50] Energy consumed for all CPUs : 0.000031 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 11:18:50] 0.000044 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [10/63], Loss: 0.6874\n",
      "Epoch [1/2], Step [20/63], Loss: 0.5844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:19:05] Energy consumed for RAM : 0.000025 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 11:19:05] Energy consumed for all CPUs : 0.000063 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 11:19:05] 0.000088 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [30/63], Loss: 0.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:19:20] Energy consumed for RAM : 0.000037 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 11:19:20] Energy consumed for all CPUs : 0.000094 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 11:19:20] 0.000131 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [40/63], Loss: 0.6217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:19:35] Energy consumed for RAM : 0.000050 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 11:19:35] Energy consumed for all CPUs : 0.000125 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 11:19:35] 0.000175 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [50/63], Loss: 0.5839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:19:50] Energy consumed for RAM : 0.000062 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 11:19:50] Energy consumed for all CPUs : 0.000156 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 11:19:50] 0.000219 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [60/63], Loss: 0.6780\n",
      "Epoch [1/2], Average Loss: 0.6246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:20:05] Energy consumed for RAM : 0.000075 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 11:20:05] Energy consumed for all CPUs : 0.000188 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 11:20:05] 0.000262 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Step [10/63], Loss: 0.5801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:20:20] Energy consumed for RAM : 0.000087 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 11:20:20] Energy consumed for all CPUs : 0.000219 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 11:20:20] 0.000306 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Step [20/63], Loss: 0.5409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:20:35] Energy consumed for RAM : 0.000100 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 11:20:35] Energy consumed for all CPUs : 0.000250 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 11:20:35] 0.000350 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 11:20:35] 0.000163 g.CO2eq/s mean an estimation of 5.153690782634176 kg.CO2eq/year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Step [30/63], Loss: 0.5709\n",
      "Epoch [2/2], Step [40/63], Loss: 0.6908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:20:50] Energy consumed for RAM : 0.000112 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 11:20:50] Energy consumed for all CPUs : 0.000281 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 11:20:50] 0.000394 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Step [50/63], Loss: 0.5604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:21:05] Energy consumed for RAM : 0.000125 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 11:21:05] Energy consumed for all CPUs : 0.000313 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 11:21:05] 0.000437 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Step [60/63], Loss: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:21:15] Energy consumed for RAM : 0.000133 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 11:21:15] Energy consumed for all CPUs : 0.000334 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 11:21:15] 0.000467 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Average Loss: 0.5949\n",
      "Training completed. Total CO2 emissions: 2.6173939494704938e-05 kg\n"
     ]
    }
   ],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=2, max_batches=100):\n",
    "    # Initialize CodeCarbon tracker\n",
    "    tracker = EmissionsTracker()\n",
    "    tracker.start()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch_idx, (spectrograms, labels) in enumerate(train_loader):\n",
    "            if batch_idx >= max_batches:  # Stop after max_batches\n",
    "                break\n",
    "            \n",
    "            labels = labels.unsqueeze(1).float()  # Reshape labels to (batch_size, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(spectrograms)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Log loss\n",
    "            running_loss += loss.item()\n",
    "            if (batch_idx + 1) % 10 == 0:  # Log every 10 batches\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Stop the tracker and print emissions\n",
    "    emissions = tracker.stop()\n",
    "    print(f\"Training completed. Total CO2 emissions: {emissions} kg\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to cnn_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model (optional)\n",
    "torch.save(model.state_dict(), \"./models/cnn_model.pth\")\n",
    "print(\"Model saved to cnn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the test dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained CNN model.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        for spectrograms, labels in test_loader:\n",
    "            try:\n",
    "                outputs = model(spectrograms)\n",
    "                predicted = (outputs > 0.5).float()  # Convert outputs to binary predictions\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted.squeeze() == labels).sum().item()\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping batch due to error: {e}\")\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahlenet/Desktop/FrugalAI/venv/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1024\n",
      "  warnings.warn(\n",
      "/Users/sarahlenet/Desktop/FrugalAI/venv/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=960\n",
      "  warnings.warn(\n",
      "/Users/sarahlenet/Desktop/FrugalAI/venv/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=960\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the trained model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 14\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient computation for inference\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mspectrograms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectrograms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/FrugalAI/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Desktop/FrugalAI/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/FrugalAI/venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter))\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 91\u001b[0m, in \u001b[0;36mSpectrogramIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m label \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Process audio to spectrogram\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m spectrogram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m spectrogram, label\n",
      "Cell \u001b[0;32mIn[27], line 73\u001b[0m, in \u001b[0;36mSpectrogramIterableDataset.process_audio\u001b[0;34m(self, audio_array, sampling_rate)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Apply frequency and time masking\u001b[39;00m\n\u001b[1;32m     72\u001b[0m log_mel_spectrogram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrequency_masking(log_mel_spectrogram)\n\u001b[0;32m---> 73\u001b[0m log_mel_spectrogram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_masking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Compute delta features\u001b[39;00m\n\u001b[1;32m     76\u001b[0m log_mel_spectrogram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_delta_features(log_mel_spectrogram)\n",
      "Cell \u001b[0;32mIn[27], line 37\u001b[0m, in \u001b[0;36mSpectrogramIterableDataset.time_masking\u001b[0;34m(self, spectrogram, max_mask_time)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spectrogram\n\u001b[1;32m     36\u001b[0m time_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mmin\u001b[39m(max_mask_time, spectrogram\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure valid range\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m start \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, spectrogram\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m time_mask)\n\u001b[1;32m     38\u001b[0m spectrogram[:, start:start \u001b[38;5;241m+\u001b[39m time_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spectrogram\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:782\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnumpy/random/_bounded_integers.pyx:1334\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model\n",
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
